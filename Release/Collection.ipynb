{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Stocks Using Machine Learning\n",
    "## Collection\n",
    "<hr>\n",
    "\n",
    "The goal of this notebook is to provide collection methods for attributes that we believe will be important to predicting a stock's price movement. After collection and compiliation into a dataframe, data will be pickled for Cleaning and EDA.\n",
    "\n",
    "### Objectives\n",
    " - Collect Ticker and Date\n",
    " - Collect Open Price\n",
    " - Collect Close Price\n",
    " - Collect Volume\n",
    " - Collect News Sentiment Score\n",
    "    - Full article sentiment more accurate than just headline (perform on full content if possible)\n",
    " - Collect Social Sentiment Score\n",
    " - Collect Related Stock Sentiment Score\n",
    "   - Collect related stock tickers that are found within articles\n",
    "   - Compile into a list based on frequency\n",
    "   - Apply weighted social and news sentiment of these related stock to the primary stock\n",
    "   \n",
    "### Organization of data\n",
    "\n",
    "Data must be organized based on ticker and date. After collection is complete, a label will be applied for the **next day's** closing price to evalute whether the sentiment affects stock price.\n",
    "\n",
    "### Sample Stocks\n",
    "\n",
    "Due to the need to collect articles on both the original ticker, and any ticker collected while reading articles, we will limit collect to various stocks across different industries.\n",
    "\n",
    " - Tech\n",
    "   - UBER\n",
    "   - FB\n",
    "   - ORCL\n",
    "   - PYPL\n",
    "   - CSCO\n",
    "   - MSFT\n",
    " - Finance\n",
    "   - BAC\n",
    "   - WFC\n",
    "   - C\n",
    "   - JPM\n",
    "   - V\n",
    "   - MS\n",
    " - Electronics\n",
    "   - AMD\n",
    "   - AAPL\n",
    "   - MU\n",
    "   - INTC\n",
    "   - NOK\n",
    "   - BA\n",
    " - Health\n",
    "   - PFE\n",
    "   - JNJ\n",
    " - Retail\n",
    "   - COST\n",
    "   - WMT\n",
    "   - HD\n",
    "   - CVS\n",
    "   - BABA\n",
    "   - KR\n",
    " - Energy\n",
    "   - BP\n",
    "   - XOM\n",
    "   - CVX\n",
    " - Transportation\n",
    "   - AAL\n",
    "   - DAL\n",
    "   - LUV\n",
    "   - CSX\n",
    "   - XPO\n",
    "   - UPS\n",
    " - Consumer Items (durables)\n",
    "   - F\n",
    "   - GM\n",
    "   - ATVI\n",
    "   - TSLA\n",
    "   - GT\n",
    "   - EA\n",
    "   - HMC\n",
    " - Consumer Items (non-durables)\n",
    "   - KO\n",
    "   - ABEV\n",
    "   - UAA\n",
    "   - PG\n",
    "   - NKE\n",
    "   - GIS\n",
    " - Communication\n",
    "   - T\n",
    "   - VZ\n",
    "   - TMUS\n",
    " - Services\n",
    "   - AMC\n",
    "   - VIAC\n",
    "   - MGM\n",
    "   - CMCSA\n",
    "   - DIS\n",
    "   - WEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our focus will be the last 90 days for each of the following stocks\n",
    "\n",
    "keys = [\"c3s6juiad3ie4i7q63b0\",\"c45oediad3ia3sn569mg\",\n",
    "        \"c45oeliad3ia3sn56a1g\",\"c45of1iad3ia3sn56a7g\",\n",
    "        \"c45ofn2ad3ia3sn56as0\",\"c45oftiad3ia3sn56b10\",\n",
    "        \"c3dhc1iad3icrjj6i7qg\"]\n",
    "\n",
    "#small amt to test prior to full run\n",
    "# tickers = [\"UBER\",\"FB\",\"ORCL\",\"PYPL\"]\n",
    "\n",
    "tickers = [\"UBER\",\"FB\",\"ORCL\",\"PYPL\",\"CSCO\",\"MSFT\",\"BAC\",\"WFC\",\n",
    " \"C\",\"JPM\",\"V\",\"MS\",\"AMD\",\"AAPL\",\"MU\",\"INTC\",\"NOK\",\n",
    " \"BA\",\"PFE\",\"JNJ\",\"COST\",\"WMT\",\"HD\",\"CVS\",\"BABA\",\"KR\",\n",
    " \"BP\",\"XOM\",\"CVX\",\"AAL\",\"DAL\",\"LUV\",\"CSX\",\"XPO\",\"UPS\",\n",
    " \"F\",\"GM\",\"ATVI\",\"TSLA\",\"GT\",\"EA\",\"HMC\",\"KO\",\"ABEV\",\n",
    " \"UAA\",\"PG\",\"NKE\",\"GIS\",\"T\",\"VZ\",\"TMUS\",\"AMC\",\"VIAC\",\n",
    " \"MGM\",\"CMCSA\",\"DIS\",\"WEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swaps api key to allow more frequent calls\n",
    "\n",
    "FINNHUB_API_KEY = \"c3s6juiad3ie4i7q63b0\"\n",
    "\n",
    "def swap_key(currentKey):\n",
    "    currentKey = keys.index(currentKey) + 1\n",
    "    try:\n",
    "        return keys[currentKey]\n",
    "    except:\n",
    "        #should return zero if idx out of range\n",
    "        return keys[0]\n",
    "\n",
    "# this swaps to the next key\n",
    "# FINNHUB_API_KEY = swap_key(FINNHUB_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time function for date to increment \n",
    "def increment_one_day(str_date):\n",
    "\n",
    "    _date = datetime.strptime(str_date, '%Y-%m-%d') + timedelta(days=1)\n",
    "    _date = _date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return _date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code requires the stanfordCoreNLP to be running as a local server. \n",
    "Download it and run it as a server using the commands below.\n",
    "```\n",
    "cd stanford-corenlp-4.2.2\n",
    "java -mx6g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StanfordCoreNLP Function\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "def get_sentiment(text):\n",
    "    result = nlp.annotate(text, properties={\n",
    "                   'annotators': 'sentiment',\n",
    "                   'outputFormat': 'json',\n",
    "                   'timeout': 5000,\n",
    "               })\n",
    "    return np.mean([int(i['sentimentValue']) for i in result['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets news for ticker on a specfic date.\n",
    "def get_news(ticker, date):\n",
    "    r = requests.get(f'https://finnhub.io/api/v1/company-news?symbol={ticker}&from={date}&to={date}&token={FINNHUB_API_KEY}')\n",
    "    \n",
    "    data = r.json()\n",
    "    h = []\n",
    "    for d in data:\n",
    "        d['date'] = datetime.utcfromtimestamp(d['datetime']).strftime('%Y-%m-%d')\n",
    "        h.append([d['id'], d['date'], d['headline'], d['source'], d['summary'],d['url']])\n",
    "\n",
    "    df = pd.DataFrame(h, columns=['id', 'date', 'headline', 'source', 'summary','url'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets_news_sentiment for each ticker. Usually Recent stats (last week or 2 weeks ago stats possibly.)\n",
    "def get_news_sentiment(ticker):\n",
    "    r = requests.get(f'https://finnhub.io/api/v1/news-sentiment?symbol={ticker}&token={FINNHUB_API_KEY}')\n",
    "\n",
    "    data = r.json()\n",
    "    h={}\n",
    "\n",
    "    for d in data:\n",
    "        try:\n",
    "            for i in data[d]:\n",
    "                sd=[]\n",
    "                sd.append(data[d][i])\n",
    "                h[i]=sd\n",
    "\n",
    "        except:\n",
    "            kl=[]\n",
    "            kl.append(data[d])\n",
    "            h[d]=kl\n",
    "\n",
    "    df = pd.DataFrame.from_dict(h)\n",
    "    df.insert(0,'Ticker',ticker)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_social_sent(day,symbol):\n",
    "    day2 = day[:-1] + str(int(day[-1])+1)\n",
    "\n",
    "    r = requests.get(f'https://finnhub.io/api/v1/stock/social-sentiment?symbol={symbol}&token={FINNHUB_API_KEY}&from={day}&to={day2}')\n",
    "    data = r.json()\n",
    "    \n",
    "    scores = []\n",
    "    mentions = []\n",
    "\n",
    "    for i in data['reddit']:\n",
    "        scores.append(i['score'])\n",
    "        mentions.append(i['mention'])\n",
    "    for i in data['twitter']:\n",
    "        scores.append(i['score'])\n",
    "        mentions.append(i['mention'])\n",
    "    \n",
    "    if scores:\n",
    "        products = [a * b for a, b in zip(scores, mentions)]\n",
    "        return sum(products)/sum(mentions),sum(mentions)\n",
    "    else:\n",
    "        return -1,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets open and close for \n",
    "def get_open_close(day, symbol):\n",
    "    #TODO: open close and vol collection\n",
    "    start_t = day + \" 00:00:00\"\n",
    "    end_t = day + \" 23:59:59\"\n",
    "    start_t = int(time.mktime(datetime.strptime(start_t, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "    end_t = int(time.mktime(datetime.strptime(end_t, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "\n",
    "    r = requests.get(f'https://finnhub.io/api/v1/stock/candle?symbol={symbol}&resolution=D&from={start_t}&to={end_t}&token={FINNHUB_API_KEY}')\n",
    "    data = r.json()\n",
    "    \n",
    "    try:\n",
    "        return data['o'][0],data['c'][0],data['h'][0],data['l'][0],data['v'][0]\n",
    "    except:\n",
    "        return -1,-1,-1,-1,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def relationalStock():\n",
    "    #TODO: relational stock collection\n",
    "    #this may need to be its own notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Where Magic Happens. \n",
    "# Where everything comes together.\n",
    "\n",
    "all_news = pd.DataFrame([])\n",
    "\n",
    "for ticker in tickers:\n",
    "    #start date\n",
    "    _date = '2021-03-15'\n",
    "    \n",
    "    #create empty dataframe\n",
    "    df = pd.DataFrame([])\n",
    "    \n",
    "    #stop date\n",
    "    _fdate = '2021-08-03'\n",
    "    \n",
    "    #loop over dates and get news articles and append to dataframe : limit 60 api calls per minute\n",
    "    while _date != _fdate: #datetime.today().strftime('%Y-%m-%d'):\n",
    "        df = df.append(get_news(ticker, _date))\n",
    "        df = df.drop_duplicates()\n",
    "        FINNHUB_API_KEY = swap_key(FINNHUB_API_KEY)\n",
    "        time.sleep(0.15)\n",
    "        _date = increment_one_day(_date)\n",
    "    \n",
    "    #There are some repeat headlines on the same day, so getting a daily headline count per article\n",
    "    #Maybe duplicates of the same headline indicates more important news??\n",
    "    duplicate_headlines = df[['date', 'headline', 'id']]\n",
    "    dh = (duplicate_headlines.groupby(['date', 'headline'], as_index=False)\n",
    "          .count()\n",
    "          .rename(columns={'id': 'headline_count'}))\n",
    "      \n",
    "    # Get unique headlines by date\n",
    "    no_dups = df.drop_duplicates(subset=['date', 'headline'])\n",
    "    \n",
    "    #Merge in headline counts\n",
    "    no_dups = no_dups.merge(dh, how='left', on=['date', 'headline'])\n",
    "    \n",
    "    #Insert ticker\n",
    "    no_dups.insert(0, 'ticker', ticker)\n",
    "    \n",
    "    #Append to dataframe that has all tickers\n",
    "    all_news = all_news.append(no_dups)\n",
    "    \n",
    "all_news.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the articles with same date and ticker is merged into a list.\n",
    "all_news_1=pd.DataFrame(all_news.groupby(['ticker','date'])['headline'].apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 49min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Gets the score of those list of articles for each ticker for each date\n",
    "finals=[]\n",
    "for i,j in dict(all_news_1).items():\n",
    "    for k in j:\n",
    "        score=[]\n",
    "        for l in k:\n",
    "            try: \n",
    "                score.append(get_sentiment(l))\n",
    "            except:\n",
    "                score.append(-1)\n",
    "        finals.append(round(np.mean(score),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds the sentiment score to dataframe column\n",
    "all_news_1['news_sentiment_score']=finals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds sources\n",
    "all_news_3=pd.DataFrame(all_news.groupby(['ticker','date'])['source'].apply(list))\n",
    "all_news_1[\"source\"] = all_news_3[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds url\n",
    "all_news_2=pd.DataFrame(all_news.groupby(['ticker','date'])['url'].apply(list))\n",
    "all_news_1[\"url\"] = all_news_2[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies amount of articles\n",
    "a=all_news_1.reset_index()\n",
    "a['amount_of_articles']=a['headline'].apply(lambda x: len(x))\n",
    "\n",
    "a['date'] = a['date'].apply(lambda x: datetime.strftime(x, '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# collecting the opens, closes, and vols\n",
    "opens = []\n",
    "closes =  []\n",
    "highs = []\n",
    "lows = []\n",
    "vols = []\n",
    "for idx,row in a.iterrows():\n",
    "    FINNHUB_API_KEY = swap_key(FINNHUB_API_KEY)\n",
    "    time.sleep(0.15)\n",
    "    o,c,h,l,v = get_open_close(row['date'], row['ticker'])\n",
    "    opens.append(o)\n",
    "    closes.append(c)\n",
    "    vols.append(v)\n",
    "    highs.append(h)\n",
    "    lows.append(l)\n",
    "    \n",
    "b = {'open': opens, 'close': closes, 'highs': highs, 'lows': lows, 'volume': vols}\n",
    "b = pd.DataFrame(data=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"open\"] = b[\"open\"]\n",
    "a[\"close\"] = b[\"close\"]\n",
    "a[\"volume\"] = b[\"volume\"]\n",
    "a[\"highs\"] = b[\"highs\"]\n",
    "a[\"lows\"] = b[\"lows\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# collecting sentiments\n",
    "sents=[]\n",
    "mentions=[]\n",
    "for idx,row in a.iterrows():\n",
    "    FINNHUB_API_KEY = swap_key(FINNHUB_API_KEY)\n",
    "    time.sleep(0.15)\n",
    "    s,m = get_social_sent(row['date'],row['ticker'])\n",
    "    sents.append(s)\n",
    "    mentions.append(m)\n",
    "    \n",
    "c = {'social_sentiments': sents, 'mentions': mentions}\n",
    "c = pd.DataFrame(data=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine dataframes\n",
    "a[\"social_sentiments\"] = c[\"social_sentiments\"]\n",
    "a[\"mentions\"] = c[\"mentions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>news_sentiment_score</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>amount_of_articles</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>highs</th>\n",
       "      <th>lows</th>\n",
       "      <th>social_sentiments</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>[Get Ready For A Great American Travel And Spe...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>[SeekingAlpha, DowJones, SeekingAlpha, MarketW...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=7c2dbca0b704a9...</td>\n",
       "      <td>4</td>\n",
       "      <td>24.55</td>\n",
       "      <td>25.17</td>\n",
       "      <td>94133688</td>\n",
       "      <td>25.9400</td>\n",
       "      <td>24.21</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>[American Airlines Group Inc. stock underperfo...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[MarketWatch, SeekingAlpha, SeekingAlpha]</td>\n",
       "      <td>[https://finnhub.io/api/news?id=8097e865de52b8...</td>\n",
       "      <td>3</td>\n",
       "      <td>25.11</td>\n",
       "      <td>24.47</td>\n",
       "      <td>47923579</td>\n",
       "      <td>25.2500</td>\n",
       "      <td>24.31</td>\n",
       "      <td>-0.496911</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>[American Airlines Group Inc. stock outperform...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[MarketWatch, MarketWatch, MarketWatch, DowJones]</td>\n",
       "      <td>[https://finnhub.io/api/news?id=218be0fe1534fa...</td>\n",
       "      <td>4</td>\n",
       "      <td>24.12</td>\n",
       "      <td>25.16</td>\n",
       "      <td>38540131</td>\n",
       "      <td>25.2200</td>\n",
       "      <td>23.90</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>[American Airlines Group Inc. stock underperfo...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[MarketWatch, SeekingAlpha]</td>\n",
       "      <td>[https://finnhub.io/api/news?id=c8722f77fbf8f6...</td>\n",
       "      <td>2</td>\n",
       "      <td>25.12</td>\n",
       "      <td>24.70</td>\n",
       "      <td>53368955</td>\n",
       "      <td>26.0900</td>\n",
       "      <td>24.55</td>\n",
       "      <td>-0.237848</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>[American Airlines Group Inc. stock outperform...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[MarketWatch, SeekingAlpha, MarketWatch, Seeki...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=e17f340aa8ca4b...</td>\n",
       "      <td>4</td>\n",
       "      <td>24.68</td>\n",
       "      <td>24.97</td>\n",
       "      <td>49461200</td>\n",
       "      <td>25.1100</td>\n",
       "      <td>23.88</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090</th>\n",
       "      <td>XPO</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>[GXO Logistics, Victoria's Secret &amp; GameStop S...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>[Yahoo, MarketWatch]</td>\n",
       "      <td>[https://finnhub.io/api/news?id=e652932d3709d4...</td>\n",
       "      <td>2</td>\n",
       "      <td>139.71</td>\n",
       "      <td>138.87</td>\n",
       "      <td>1363769</td>\n",
       "      <td>140.7499</td>\n",
       "      <td>137.60</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7091</th>\n",
       "      <td>XPO</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>[XPO Logistics (XPO) Tops Q2 Earnings and Reve...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[Yahoo, DowJones, Yahoo, Yahoo, MarketWatch, M...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=181ba4c8ec3180...</td>\n",
       "      <td>12</td>\n",
       "      <td>139.07</td>\n",
       "      <td>137.78</td>\n",
       "      <td>1302691</td>\n",
       "      <td>139.5364</td>\n",
       "      <td>136.14</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7092</th>\n",
       "      <td>XPO</td>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>[XPO Logistics's (XPO) CEO Brad Jacobs on Q2 2...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[SeekingAlpha]</td>\n",
       "      <td>[https://finnhub.io/api/news?id=dbd91b5ce37247...</td>\n",
       "      <td>1</td>\n",
       "      <td>137.01</td>\n",
       "      <td>141.03</td>\n",
       "      <td>1712136</td>\n",
       "      <td>144.2000</td>\n",
       "      <td>136.39</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>XPO</td>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>[The XPO-GXO Spinoff Saga: 'See You At The Cro...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[Yahoo, Yahoo, Yahoo]</td>\n",
       "      <td>[https://finnhub.io/api/news?id=8937926dfdb7b6...</td>\n",
       "      <td>3</td>\n",
       "      <td>139.57</td>\n",
       "      <td>138.69</td>\n",
       "      <td>3054300</td>\n",
       "      <td>141.0700</td>\n",
       "      <td>138.32</td>\n",
       "      <td>-0.249992</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7094</th>\n",
       "      <td>XPO</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>[GXO Adds Jason Papastavrou to Board of Direct...</td>\n",
       "      <td>1.47</td>\n",
       "      <td>[Yahoo, Yahoo, Yahoo, Yahoo, Yahoo, Yahoo, Yah...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=dc5760ae7523d4...</td>\n",
       "      <td>16</td>\n",
       "      <td>82.30</td>\n",
       "      <td>83.95</td>\n",
       "      <td>6006379</td>\n",
       "      <td>86.4199</td>\n",
       "      <td>82.30</td>\n",
       "      <td>0.166281</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7095 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker        date                                           headline  \\\n",
       "0       AAL  2021-03-15  [Get Ready For A Great American Travel And Spe...   \n",
       "1       AAL  2021-03-16  [American Airlines Group Inc. stock underperfo...   \n",
       "2       AAL  2021-03-17  [American Airlines Group Inc. stock outperform...   \n",
       "3       AAL  2021-03-18  [American Airlines Group Inc. stock underperfo...   \n",
       "4       AAL  2021-03-19  [American Airlines Group Inc. stock outperform...   \n",
       "...     ...         ...                                                ...   \n",
       "7090    XPO  2021-07-27  [GXO Logistics, Victoria's Secret & GameStop S...   \n",
       "7091    XPO  2021-07-28  [XPO Logistics (XPO) Tops Q2 Earnings and Reve...   \n",
       "7092    XPO  2021-07-29  [XPO Logistics's (XPO) CEO Brad Jacobs on Q2 2...   \n",
       "7093    XPO  2021-07-30  [The XPO-GXO Spinoff Saga: 'See You At The Cro...   \n",
       "7094    XPO  2021-08-02  [GXO Adds Jason Papastavrou to Board of Direct...   \n",
       "\n",
       "      news_sentiment_score                                             source  \\\n",
       "0                     2.25  [SeekingAlpha, DowJones, SeekingAlpha, MarketW...   \n",
       "1                     2.00          [MarketWatch, SeekingAlpha, SeekingAlpha]   \n",
       "2                     2.00  [MarketWatch, MarketWatch, MarketWatch, DowJones]   \n",
       "3                     2.00                        [MarketWatch, SeekingAlpha]   \n",
       "4                     2.00  [MarketWatch, SeekingAlpha, MarketWatch, Seeki...   \n",
       "...                    ...                                                ...   \n",
       "7090                  1.50                               [Yahoo, MarketWatch]   \n",
       "7091                  2.00  [Yahoo, DowJones, Yahoo, Yahoo, MarketWatch, M...   \n",
       "7092                  2.00                                     [SeekingAlpha]   \n",
       "7093                  2.00                              [Yahoo, Yahoo, Yahoo]   \n",
       "7094                  1.47  [Yahoo, Yahoo, Yahoo, Yahoo, Yahoo, Yahoo, Yah...   \n",
       "\n",
       "                                                    url  amount_of_articles  \\\n",
       "0     [https://finnhub.io/api/news?id=7c2dbca0b704a9...                   4   \n",
       "1     [https://finnhub.io/api/news?id=8097e865de52b8...                   3   \n",
       "2     [https://finnhub.io/api/news?id=218be0fe1534fa...                   4   \n",
       "3     [https://finnhub.io/api/news?id=c8722f77fbf8f6...                   2   \n",
       "4     [https://finnhub.io/api/news?id=e17f340aa8ca4b...                   4   \n",
       "...                                                 ...                 ...   \n",
       "7090  [https://finnhub.io/api/news?id=e652932d3709d4...                   2   \n",
       "7091  [https://finnhub.io/api/news?id=181ba4c8ec3180...                  12   \n",
       "7092  [https://finnhub.io/api/news?id=dbd91b5ce37247...                   1   \n",
       "7093  [https://finnhub.io/api/news?id=8937926dfdb7b6...                   3   \n",
       "7094  [https://finnhub.io/api/news?id=dc5760ae7523d4...                  16   \n",
       "\n",
       "        open   close    volume     highs    lows  social_sentiments  mentions  \n",
       "0      24.55   25.17  94133688   25.9400   24.21          -1.000000        -1  \n",
       "1      25.11   24.47  47923579   25.2500   24.31          -0.496911         2  \n",
       "2      24.12   25.16  38540131   25.2200   23.90           0.014636        21  \n",
       "3      25.12   24.70  53368955   26.0900   24.55          -0.237848        20  \n",
       "4      24.68   24.97  49461200   25.1100   23.88          -1.000000        -1  \n",
       "...      ...     ...       ...       ...     ...                ...       ...  \n",
       "7090  139.71  138.87   1363769  140.7499  137.60          -1.000000        -1  \n",
       "7091  139.07  137.78   1302691  139.5364  136.14          -1.000000        -1  \n",
       "7092  137.01  141.03   1712136  144.2000  136.39          -1.000000        -1  \n",
       "7093  139.57  138.69   3054300  141.0700  138.32          -0.249992         4  \n",
       "7094   82.30   83.95   6006379   86.4199   82.30           0.166281         6  \n",
       "\n",
       "[7095 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the final dataframe\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a HDF5 because it saves and loads fast\n",
    "a.to_hdf('stocksFull.h5', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use below code to recover dataframe\n",
    "#reread = pd.read_hdf('stocks.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
